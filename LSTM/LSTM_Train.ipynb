{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:06.912721Z",
     "start_time": "2024-06-04T14:27:06.905738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#import data\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1d0f7ee2dd11ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.861727Z",
     "start_time": "2024-06-04T14:27:06.929721Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===trin data file path=== \n",
      " c:\\github_JM\\2024-Neural-networks-and-deep-learning-teamproject\\dataset\\traindata\\drive_data_train.csv\n"
     ]
    }
   ],
   "source": [
    "all_x_data = []\n",
    "all_y_data = []\n",
    "\n",
    "file_path = os.path.join(\"..\",\"dataset\",\"traindata\",\"drive_data_train.csv\")\n",
    "file_path = os.path.abspath(file_path)\n",
    "print(\"===trin data file path===\", \"\\n\", file_path)\n",
    "\n",
    "# Pandas를 이용해 파일 읽기\n",
    "data = pd.read_csv(file_path, sep=\",\", header=0, dtype=float)\n",
    "x_data = torch.tensor(data.iloc[:, [0,2,3,4,5]].values, dtype=torch.float32)\n",
    "y_data = torch.tensor(data.iloc[:, 1:2].values, dtype=torch.float32)\n",
    "\n",
    "# 전체 데이터 리스트에 추가\n",
    "all_x_data.append(x_data)\n",
    "all_y_data.append(y_data)\n",
    "        \n",
    "# 리스트에 저장된 모든 데이터를 하나의 텐서로 결합\n",
    "all_x_data = torch.cat(all_x_data, dim=0)\n",
    "all_y_data = torch.cat(all_y_data, dim=0)\n",
    "\n",
    "# 전체 데이터에 대한 평균과 분산 계산\n",
    "mean_x = torch.mean(all_x_data, dim=0)\n",
    "std_x = torch.std(all_x_data, dim=0)\n",
    "\n",
    "Max_Vy = max(abs(all_y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf1f02692364ad14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.876728Z",
     "start_time": "2024-06-04T14:27:07.862720Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = (all_x_data - mean_x) / std_x  # mean과 std는 훈련 데이터셋에서 계산된 값 사용\n",
    "y_data = all_y_data/float(Max_Vy)\n",
    "\n",
    "# 배치사이즈 설정\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6984a4bf16a08256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.892720Z",
     "start_time": "2024-06-04T14:27:07.877721Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class My_dataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):  #데이터 셋 선처리 해주는 부분\n",
    "        self.x_data = x_data.unsqueeze(1)\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x_data[index]  # (1, input_size) 형식\n",
    "        y = self.y_data[index]  # (1) 형식\n",
    "\n",
    "        if self.transform:\n",
    "            x, y = self.transform((x, y))\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        x = torch.FloatTensor(x)\n",
    "        y = torch.FloatTensor(y)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "trans = transforms.Compose([ToTensor()])\n",
    "\n",
    "train_data = My_dataset(x_data, y_data, transform=trans)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc26889deb2d5213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.907726Z",
     "start_time": "2024-06-04T14:27:07.893720Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 시점의 출력만 사용\n",
    "        out = self.tanh(out)  # tanh 활성화 함수 적용\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# 모델 초기화 및 손실 함수, 옵티마이저 설정\n",
    "input_size = 5\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMNet(input_size, hidden_size, num_layers, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "834d5a1f74018627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.923726Z",
     "start_time": "2024-06-04T14:27:07.908721Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3416eb3b50b29bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.939726Z",
     "start_time": "2024-06-04T14:27:07.924720Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51521\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb332b0a0d383d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T14:29:24.542641Z",
     "start_time": "2024-06-04T14:27:07.940720Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===trained model path=== \n",
      " c:\\github_JM\\2024-Neural-networks-and-deep-learning-teamproject\\LSTM\\model\\LSTM_model_2024_06_05_19_44.pt\n",
      "Epoch 0, average_losses: 0.02028804910127827\n",
      "Epoch 1, average_losses: 0.01778512915796669\n",
      "Epoch 2, average_losses: 0.015141648871076005\n",
      "Training interrupted. Saving the model.\n",
      "Traced model saved.\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "model_path = os.path.join(\"model\",\"LSTM_model_{0}.pt\".format(formatted_time))\n",
    "model_path = os.path.abspath(model_path)\n",
    "print(\"===trained model path===\", \"\\n\", model_path)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# 훈련 루프\n",
    "num_epochs = 600\n",
    "num_data = len(x_data)\n",
    "\n",
    "\n",
    "min_loss = 50\n",
    "training_epoch = 0\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        epoch_losses = []\n",
    "        average_losses = []\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs  # LSTM 입력 형태에 맞게 변경 (batch_size, seq_len, input_size)\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.view(-1, 1)\n",
    "            \n",
    "            loss = Loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "    \n",
    "        average_losses = np.mean(epoch_losses)\n",
    "        losses.append(average_losses)\n",
    "    \n",
    "        if average_losses < min_loss:\n",
    "            min_loss = average_losses\n",
    "            model.eval()  # 모델 평가 모드로 전환\n",
    "            x_dummy = torch.randn(1, 1, input_size)\n",
    "            traced_model = torch.jit.trace(model, x_dummy)\n",
    "            traced1_model_path = model_path[:-3] + '_Traced_1.pt'\n",
    "            torch.jit.save(traced_model, traced1_model_path)\n",
    "\n",
    "        if epoch in [100,200,300,400]:\n",
    "            model.eval()  # 모델을 평가 모드로 설정\n",
    "            x_dummy = torch.randn(1, 1, input_size)\n",
    "            traced_model = torch.jit.trace(model, x_dummy)\n",
    "            evaluated_model_path = model_path[:-3] + '_Evaluated_' + str(epoch) + '.pt'\n",
    "            torch.jit.save(traced_model, evaluated_model_path)\n",
    "\n",
    "        # Scheduler 업데이트\n",
    "        scheduler.step()\n",
    "        training_epoch = epoch\n",
    "        # 진행 상황 출력 (선택적)\n",
    "        print(f\"Epoch {epoch}, average_losses: {average_losses}\")        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving the model.\")\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    x_dummy = torch.randn(1, 1, input_size)\n",
    "    traced_model = torch.jit.trace(model, x_dummy)\n",
    "    # 트레이싱된 모델 저장\n",
    "    traced2_model_path = model_path[:-3] + '_Traced_2.pt'\n",
    "    torch.jit.save(traced_model, traced2_model_path)\n",
    "\n",
    "# 모델 저장\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "x_dummy = torch.randn(1, 1, input_size)\n",
    "traced_model = torch.jit.trace(model, x_dummy)\n",
    "\n",
    "# 트레이싱된 모델 저장\n",
    "traced3_model_path = model_path[:-3] + '_Traced_3.pt'\n",
    "torch.jit.save(traced_model, traced3_model_path)\n",
    "print(\"Traced model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
