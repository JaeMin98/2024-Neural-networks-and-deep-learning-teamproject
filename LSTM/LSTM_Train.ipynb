{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:06.912721Z",
     "start_time": "2024-06-04T14:27:06.905738Z"
    }
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#import data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.onnx\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 파일이 위치한 디렉토리 경로\n",
    "directory_path = r'C:\\Users\\kyos1\\Desktop\\Neural Network data\\Pytorch_train_data'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:06.928721Z",
     "start_time": "2024-06-04T14:27:06.916721Z"
    }
   },
   "id": "372a66c5ad9e9e19",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_x_data = []\n",
    "all_y_data = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # Pandas를 이용해 파일 읽기\n",
    "        data = pd.read_csv(file_path, sep=\",\", header=0, dtype=float)\n",
    "        x_data = torch.tensor(data.iloc[:, [0,2,3,4,5]].values, dtype=torch.float32)\n",
    "        y_data = torch.tensor(data.iloc[:, 1:2].values, dtype=torch.float32)\n",
    "        \n",
    "        # 전체 데이터 리스트에 추가\n",
    "        all_x_data.append(x_data)\n",
    "        all_y_data.append(y_data)\n",
    "        \n",
    "# 리스트에 저장된 모든 데이터를 하나의 텐서로 결합\n",
    "all_x_data = torch.cat(all_x_data, dim=0)\n",
    "all_y_data = torch.cat(all_y_data, dim=0)\n",
    "\n",
    "# 전체 데이터에 대한 평균과 분산 계산\n",
    "mean_x = torch.mean(all_x_data, dim=0)\n",
    "std_x = torch.std(all_x_data, dim=0)\n",
    "\n",
    "Max_Vy = max(abs(all_y_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.861727Z",
     "start_time": "2024-06-04T14:27:06.929721Z"
    }
   },
   "id": "8b1d0f7ee2dd11ce",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_data = (all_x_data - mean_x) / std_x  # mean과 std는 훈련 데이터셋에서 계산된 값 사용\n",
    "y_data = all_y_data/float(Max_Vy)\n",
    "\n",
    "# 배치사이즈 설정\n",
    "batch_size = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.876728Z",
     "start_time": "2024-06-04T14:27:07.862720Z"
    }
   },
   "id": "bf1f02692364ad14",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class My_dataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):  #데이터 셋 선처리 해주는 부분\n",
    "        self.x_data = x_data.unsqueeze(1)\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x_data[index]  # (1, input_size) 형식\n",
    "        y = self.y_data[index]  # (1) 형식\n",
    "\n",
    "        if self.transform:\n",
    "            x, y = self.transform((x, y))\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        x = torch.FloatTensor(x)\n",
    "        y = torch.FloatTensor(y)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "trans = transforms.Compose([ToTensor()])\n",
    "\n",
    "train_data = My_dataset(x_data, y_data, transform=trans)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.892720Z",
     "start_time": "2024-06-04T14:27:07.877721Z"
    }
   },
   "id": "6984a4bf16a08256",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 시점의 출력만 사용\n",
    "        out = self.tanh(out)  # tanh 활성화 함수 적용\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# 모델 초기화 및 손실 함수, 옵티마이저 설정\n",
    "input_size = 5\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMNet(input_size, hidden_size, num_layers, output_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.907726Z",
     "start_time": "2024-06-04T14:27:07.893720Z"
    }
   },
   "id": "dc26889deb2d5213",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.99)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.923726Z",
     "start_time": "2024-06-04T14:27:07.908721Z"
    }
   },
   "id": "834d5a1f74018627",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51521\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:27:07.939726Z",
     "start_time": "2024-06-04T14:27:07.924720Z"
    }
   },
   "id": "c3416eb3b50b29bb",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average_losses: 0.025432577548891236\n",
      "Epoch 1, average_losses: 0.02108662089916113\n",
      "Epoch 2, average_losses: 0.019067802205478622\n",
      "Epoch 3, average_losses: 0.017858773277283652\n",
      "Epoch 4, average_losses: 0.01684435142244252\n",
      "Epoch 5, average_losses: 0.015876680832078355\n",
      "Epoch 6, average_losses: 0.014948752327912205\n",
      "Epoch 7, average_losses: 0.014062456646055545\n",
      "Epoch 8, average_losses: 0.013206050445763328\n",
      "Epoch 9, average_losses: 0.012359973805256953\n",
      "Epoch 10, average_losses: 0.011504934452016145\n",
      "Epoch 11, average_losses: 0.010626893207202401\n",
      "Epoch 12, average_losses: 0.009719225106102455\n",
      "Epoch 13, average_losses: 0.008783455147286592\n",
      "Epoch 14, average_losses: 0.007829532290002736\n",
      "Epoch 15, average_losses: 0.006875639021361493\n",
      "Epoch 16, average_losses: 0.005946992275020643\n",
      "Epoch 17, average_losses: 0.005073085563880049\n",
      "Epoch 18, average_losses: 0.0042832242928990075\n",
      "Epoch 19, average_losses: 0.003601028421676261\n",
      "Epoch 20, average_losses: 0.0030395064683068755\n",
      "Epoch 21, average_losses: 0.0025986323335705237\n",
      "Epoch 22, average_losses: 0.0022664966878471874\n",
      "Epoch 23, average_losses: 0.002023482395860862\n",
      "Epoch 24, average_losses: 0.0018475536945807794\n",
      "Epoch 25, average_losses: 0.0017186073278798227\n",
      "Epoch 26, average_losses: 0.001620799665222464\n",
      "Epoch 27, average_losses: 0.0015429528874040632\n",
      "Epoch 28, average_losses: 0.0014778139374923413\n",
      "Epoch 29, average_losses: 0.0014209464712140925\n",
      "Epoch 30, average_losses: 0.0013697276099093251\n",
      "Epoch 31, average_losses: 0.0013226228265749633\n",
      "Epoch 32, average_losses: 0.001278720884586636\n",
      "Epoch 33, average_losses: 0.0012374606472323375\n",
      "Epoch 34, average_losses: 0.0011984790936830389\n",
      "Epoch 35, average_losses: 0.0011615267972990965\n",
      "Epoch 36, average_losses: 0.001126422594612484\n",
      "Epoch 37, average_losses: 0.0010930269564201841\n",
      "Epoch 38, average_losses: 0.0010612273420708832\n",
      "Epoch 39, average_losses: 0.0010309290695109873\n",
      "Epoch 40, average_losses: 0.001002049522198059\n",
      "Epoch 41, average_losses: 0.0009745142552279538\n",
      "Epoch 42, average_losses: 0.0009482549509623325\n",
      "Epoch 43, average_losses: 0.0009232080135676233\n",
      "Training interrupted. Saving the model.\n",
      "Traced model saved.\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "# 훈련 루프\n",
    "num_epochs = 600\n",
    "num_data = len(x_data)\n",
    "\n",
    "\n",
    "min_loss = 50\n",
    "training_epoch = 0\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        epoch_losses = []\n",
    "        average_losses = []\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs  # LSTM 입력 형태에 맞게 변경 (batch_size, seq_len, input_size)\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.view(-1, 1)\n",
    "            \n",
    "            loss = Loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "    \n",
    "        average_losses = np.mean(epoch_losses)\n",
    "        losses.append(average_losses)\n",
    "    \n",
    "        if average_losses < min_loss:\n",
    "            min_loss = average_losses\n",
    "            model.eval()  # 모델 평가 모드로 전환\n",
    "            x_dummy = torch.randn(1, 1, input_size)\n",
    "            traced_model = torch.jit.trace(model, x_dummy)\n",
    "            torch.jit.save(traced_model, r'C:\\Users\\kyos1\\Desktop\\Neural Network data\\0531_model_1.pt')\n",
    "\n",
    "        if epoch in [100,200,300,400]:\n",
    "            model.eval()  # 모델을 평가 모드로 설정\n",
    "            x_dummy = torch.randn(1, 1, input_size)\n",
    "            traced_model = torch.jit.trace(model, x_dummy)\n",
    "            torch.jit.save(traced_model, rf'C:\\Users\\kyos1\\Desktop\\Neural Network data\\0531_model_{epoch}.pt')\n",
    "\n",
    "        # Scheduler 업데이트\n",
    "        scheduler.step()\n",
    "        training_epoch = epoch\n",
    "        # 진행 상황 출력 (선택적)\n",
    "        print(f\"Epoch {epoch}, average_losses: {average_losses}\")        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted. Saving the model.\")\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    x_dummy = torch.randn(1, 1, input_size)\n",
    "    traced_model = torch.jit.trace(model, x_dummy)\n",
    "    # 트레이싱된 모델 저장\n",
    "    torch.jit.save(traced_model, r'C:\\Users\\kyos1\\Desktop\\Neural Network data\\0531_model_2.pt')\n",
    "\n",
    "# 모델 저장\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "x_dummy = torch.randn(1, 1, input_size)\n",
    "traced_model = torch.jit.trace(model, x_dummy)\n",
    "\n",
    "# 트레이싱된 모델 저장\n",
    "torch.jit.save(traced_model, r'C:\\Users\\kyos1\\Desktop\\Neural Network data\\0531_model_3.pt')\n",
    "print(\"Traced model saved.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T14:29:24.542641Z",
     "start_time": "2024-06-04T14:27:07.940720Z"
    }
   },
   "id": "7eb332b0a0d383d1",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
